import numpy as np
import os
import glob
import subprocess
import pdb


def download_heasarc(heasarc_files):
    """
    Using the observation table from query_heasarc, create a download script,
    download the data, and unzip everything.  All files will be saved into the
    same directory as the HEASARC observation table.

    Parameters
    ----------
    heasarc_files : list of strings
        Name(s) of the file(s) with the observation table generated by
        query_heasarc.py
    """

    for filename in heasarc_files:

        # galaxy name
        gal_name = filename.split('/')[-2]
    
        # read in the query output
        with open(filename, 'r') as fh:
            rows_list = fh.readlines()

        if len(rows_list) == 1:
            print("No observations of " + gal_name + " were found in HEASARC.")
            dir_path = '*/*/*/' + gal
            r = glob.glob(dir_path)
            for i in r:
                os.remove(i)
            continue

        #run browse_extract with all of the parameters needed to make data.dat

        #important inputs for loadtxt:
        #comments: comments out last line that lists number of observations returned for an object
        #skiprows: skips first two rows in data.dat that are just for formatting

        #obslist = np.loadtxt(filename, dtype = 'str', delimiter = '|',
        #                         comments = 'S', skiprows = 2, usecols = (1,2)).tolist()
        obslist = np.loadtxt(filename, dtype = 'str', delimiter = '|',
                                 skiprows=3, comments='B', usecols = (1,2)).tolist()
        id_list = list()

        #if obslist is empty:
        #    continue to next obj in obj_list, though if there's nothing that comes next, will it just end the program?

        # prefix for all of the wget commands
        save_path = '/'.join( os.path.realpath(filename).split('/')[:-1] )
        wget_prefix = "wget -q -nH --no-check-certificate --cut-dirs=5 -r -l0 -c -N -np -R 'index*' -erobots=off --directory-prefix="+save_path+" --retr-symlinks https://heasarc.gsfc.nasa.gov/FTP/swift/data/obs/"

        # path+name for download file
        download_file = os.path.dirname(filename) + '/download.scr'
        
        # make sure download script doesn't exist
        if os.path.isfile(download_file):
            os.remove(download_file)
            

        #condition that handles cases where HEASARC query returns only one row or zero rows
        if len(obslist[0]) > 2:
            #print(obslist)
            obsid = obslist[0]
            starttime = obslist[1]
            start_month = starttime[0:7]
            start_month = start_month.replace('-','_')
            id_list.append(obsid)

        #    string addition to make wget commands for data download
            wget_uvot = wget_prefix + start_month + '//' + obsid + "/uvot/"
            wget_auxil = wget_prefix + start_month + '//' + obsid + "/auxil/"

            with open(download_file, 'a') as download_scr:
                download_scr.write(wget_uvot + '\n')
                download_scr.write(wget_auxil + '\n')
                #download_scr.write('mv '+obsid+' '+obj+'/ \n')
            
        elif len(obslist[0]) == 0:
            print("* Search of table swiftmastr around "+obj+" with a radius 5' returns 0 rows")
            print("* Looks like there's no observation data for this object.")
            print("* Check to make sure that this object has been observed. Moving on...")
            continue

        else:
            for i in range(len(obslist)):
                #print(obslist[i])
                [obsid, starttime] = obslist[i]
        
                start_month = starttime[0:7]
                start_month = start_month.replace('-','_')
                id_list.append(obsid)
        
            #    string addition to make wget commands for data download
                wget_uvot = wget_prefix + start_month + '//' + obsid + "/uvot/"
                wget_auxil = wget_prefix + start_month + '//' + obsid + "/auxil/"

                with open(download_file, 'a') as download_scr:
                    download_scr.write(wget_uvot + '\n')
                    download_scr.write(wget_auxil + '\n')
                    #download_scr.write('mv '+obsid+' '+obj+'/ \n')

        #run the download script here and put the results in the directories created at the beginning of the list

        #make download script executable
        print("* running download script for "+gal_name)
        os.system('sh '+download_file)

        #unzip all the downloaded data
        print('* unzipping files')
        for i in id_list:
            gz_files = glob.glob(os.path.dirname(filename)+'/'+i+'/**/*.gz', recursive=True)
            for gz in gz_files:
                subprocess.run('gunzip '+gz, shell=True)
    

