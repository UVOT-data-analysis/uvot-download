import numpy as np
import os
import glob
import subprocess
import pdb
from astropy.io import ascii


def download_heasarc(heasarc_files, unzip=True, download_all=False,
                         download_filters=None):
    """
    Using the observation table from query_heasarc, create a download script,
    download the data, and unzip everything.  All files will be saved into the
    same directory as the HEASARC observation table.

    Parameters
    ----------
    heasarc_files : string or list of strings
        Name(s) of the file(s) with the observation table(s) generated by
        query_heasarc.py

    unzip : boolean (default=True)
        Choose whether to unzip all of the downloaded files

    download_all : boolean (default=False)
        If True, download all data.  If False, only download new data (as
        determined by existence of a folder with the relevant obsid).

    download_filters : list of strings (default=None)
        Only download data for a given obsid if one of these filters is
        present.  Allowed filters are:
          w2, m2, w1, uu, bb, vv, wh, gu, gv
        If a filter is requested but the info isn't in the heasarc_file, it
        will be assumed that observations in that filter exist.  When set to
        the default (None), all data will be downloaded.

    """

    # check if input is string or list
    if type(heasarc_files) == str:
        file_list = [heasarc_files]
    if type(heasarc_files) == list:
        file_list = heasarc_files

    # check that download_filters is set properly
    if download_filters is not None:
        for item in download_filters:
            if item not in ['w2','m2','w1','uu','bb','vv','wh','gu','gv']:
                print(item, ' is not allowed in download_filters')
                return
    

    for filename in file_list:

        # galaxy name
        gal_name = os.path.realpath(filename).split('/')[-2]
    
        # read in the query output
        with open(filename, 'r') as fh:
            rows_list = fh.readlines()

        # the file has 2 lines if there aren't any observations
        if len(rows_list) == 2:
            print("No observations of " + gal_name + " were found in HEASARC.")
            dir_path = os.path.dirname(filename)
            r = glob.glob(dir_path)
            #for i in r:
            #    os.remove(i)
            continue

        # read heasarc table with astropy table!
        heasarc_table = ascii.read(filename, format='fixed_width_two_line', comment='B', delimiter='+')


        # path where things will get saved
        save_path = '/'.join( os.path.realpath(filename).split('/')[:-1] )

        # prefix for all of the wget commands
        wget_prefix = "wget -q -nH --no-check-certificate --cut-dirs=5 -r -l0 -c -N -np -R 'index*' -erobots=off --directory-prefix="+save_path+" --retr-symlinks https://heasarc.gsfc.nasa.gov/FTP/swift/data/obs/"

        # path+name for download file
        download_file = save_path + '/download.scr'
        
        # make sure download script doesn't exist
        if os.path.isfile(download_file):
            os.remove(download_file)
                       

        for i in range(len(heasarc_table)):
           
            # if user only wants to download some filters, do corresponding checks
            if download_filters is not None:
                filter_check = download_filter_check(heasarc_table[i], download_filters)
                if filter_check == False:
                    continue
            
            obsid = str(heasarc_table['obsid'][i])
            starttime = heasarc_table['start_time'][i]
        
            start_month = starttime[0:7]
            start_month = start_month.replace('-','_')
        
            #    string addition to make wget commands for data download
            wget_uvot = wget_prefix + start_month + '//' + obsid + "/uvot/"
            wget_auxil = wget_prefix + start_month + '//' + obsid + "/auxil/"

            # only add this observation to the script if:
            # - folder for this obsid doesn't exist
            # - folder does exist, but download_all is True
            if (not os.path.isdir(save_path+'/'+obsid)) or (os.path.isdir(save_path+'/'+obsid) and download_all==True):
                with open(download_file, 'a') as download_scr:
                    download_scr.write(wget_uvot + '\n')
                    download_scr.write(wget_auxil + '\n')

        #run the download script here and put the results in the directories created at the beginning of the list


        # run download script
        # (but only if there are items to download)
        if os.path.isfile(download_file):
            print("* running download script for "+gal_name)
            os.system('sh '+download_file)
        else:
            print('* no new observations of '+gal_name+' to download')

        #unzip all the downloaded data
        if unzip:
            print('* unzipping files')
            for i in id_list:
                gz_files = glob.glob(save_path+'/'+i+'/**/*.gz', recursive=True)
                for gz in gz_files:
                    # only unzip if the unzipped file doesn't exist
                    if not os.path.isfile(gz[:-3]):
                        subprocess.run('gunzip '+gz, shell=True)
    



def download_filter_check(heasarc_table, download_filters):
    """
    Quick wrapper to do the checking for whether to download a given observation
    """

    download_data = [True] * len(download_filters)

    for f,filt in enumerate(download_filters):

        if 'uvot_expo_'+filt in heasarc_table.colnames:
            if heasarc_table['uvot_expo_'+filt] < 1e-2:
                download_data[f] = False

    if True in download_data:
        return True
    else:
        return False
